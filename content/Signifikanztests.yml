_id: 5493aa9a45ac10a752054074
position: 7
title: Signifikanztests
subtitle: Gruppenunterschiede
description: |
  In den Sozialwissenschaften sehr geläufig sind Fragestellungen nach Gruppenunterschieden. Bei der statistischen Signifikanz geht es darum, ob man gefundene Gruppenunterschiede in Stichproben auf die Population übertragen kann. Die Gruppenunterschiede müssen signifikant (bedeutsam) genug sein, damit wir sie verallgemeinern können. Signifikanz wird mit einem Signifikanztest geprüft, einem Verfahren aus der Inferenzstatistik. Es gibt für alle möglichen Szenarien und Fragestellungen passende Signifikanztests. Du lernst hier einige von ihnen kennen und anzuwenden.
  
topics:
  - _id: 54ca9effaa9e83ef4888fa8e
    title: Signifikanztests
    subtitle: Gruppenunterschiede
    body: |
      Sie haben jetzt einen Überblick über die allgemeinen Belange der Inferenzstatistik. Daran können wir jetzt ein sehr konkretes Thema anschließen, nämlich die Signifikanztests. Diese testen, ob zwischen zwei Stichproben ein bedeutsamer Mittelwertunterschied besteht. Mit bedeutsam ist im Grunde gemeint, dass man den gefundenen Mittelwertunterschied auch auf die Population übertragen darf. In unserem Denktrainingsexperiment entscheidet der Signifikanztest z.B. darüber, ob die Schüler nur in unserem Experiment nach dem Training bessere Schulleistungen zeigen als vorher, oder ob wir das auf alle Absolventen des Denktrainings ausweiten dürfen. Wir schauen uns nun an, wie man das herausfindet.
  - _id: 54ca9f15aa9e83ef4888fa8f
    title: Grundlegende Funktionsweise
    body: |
      Wir haben ja vorhin schon erfahren, dass Stichprobenmittelwerte einer Population normalverteilt sind. Praktischerweise sind auch die Differenzen der Stichprobenmittelwerte normalverteilt. Auf diesem Umstand basiert das ganze Signifikanztesten. Diese Normalverteilung hat einen Mittelwert von 0. Die meisten Mittelwertunterschiede sind gering bis 0, je extremer der Unterschied, desto seltener kommt er vor. Das heißt nun, wenn unser gefundener Mittelwertunterschied eine gewisse Extremheit besitzt und dementsprechend unwahrscheinlich ist, ist es relativ unwahrscheinlich, dass beide Mittelwerte aus der selben Population kommen. Stattdessen ist es eher anzunehmen, dass einer davon eigentlich ein Stichprobenmittelwert aus einer anderen Population ist, womit unser Populationsunterschied gefunden wäre. 
      
      Denn das ist tatsächlich die Frage: Sind Trainingsabsolventen und Nichtabsolventen verschiedene Populationen oder spielt das Training gar keine Rolle, sodass beide zur selben Population gehören? Wenn unser Mittelwertunterschied in der Normalverteilung der Mittelwertunterschiede weit genug außen liegt, nehmen wir an, dass die beiden Mittelwerte zu unterschiedlichen Populationen gehören, auch wenn es natürlich eine gewisse Irrtumswahrscheinlichkeit dafür gibt, dass sie doch beide zur gleichen Population gehören und das Training keinen Unterschied bewirkt. Dieses „weit genug außen“ ist eine Konventionsfrage und heißt Signifikanzniveau (α). Wir legen meistens ein Niveau von 5% an, also die beiden äußeren Enden der Normalverteilung, deren Flächenanteil zusammen 5% der Verteilung ausmachen, also jeweils links und rechts 2,5%. Wenn sich unser Mittelwertunterschied in diesen Flächenbereichen aufhält, besteht eine Wahrscheinlichkeit von 5%, dass es keinen Populationsunterschied gibt und eine von 95%, dass es einen gibt. Man kann auch die ganzen 5% auf eine Seite der Verteilung legen, statt sie auf beide Seiten aufzuteilen, aber dann ist das Ergebnis eben nur signifikant, wenn unser Mittelwertunterschied in diesem Flächenanteil liegt. Das wird seltener gemacht, weil man damit im Grunde schon vorweg nimmt, dass ein Stichprobenmittelwert größer ist als der andere.
      
      Die Standardabweichung für die Normalverteilung der Mittelwertunterschiede muss wie beim Standardfehler des Mittelwerts als Kennwert bestimmt werden. Und er heißt logischerweise Standardfehler des Mittelwertunterschieds, weil es ja darum geht, wie breit die Mittelwertunterschiede um die 0 streuen. Hier geht auch wieder die Repräsentativität und Größe der Stichproben mit ein, genau wie beim Standardfehler des Mittelwerts. 
  - _id: 54ca9f50aa9e83ef4888fa90
    title: t-Test
    body: |
      Wir führen jetzt einen t-Test an unseren Stichprobendaten durch. Der t-Test ist ein sehr häufig eingesetzter Signifikanztest, der zwei Stichproben bzw. deren Mittelwertunterschied auf Signifikanz hin untersuchen kann. Wir möchten wissen, ob Einzel- und Gruppentraining unterschiedlich stark auf die Intelligenz gewirkt haben. Wir brauchen also die Variable Intelligenz_nachher, die Werte für Einzel- und Gruppentraining. Die Intelligenz der drei Trainingsformgruppen wurde vor dem Experiment gematcht, also für jeden Teilnehmer im Einzeltraining wurden für Paar- und Gruppentraining gleich intelligente Teilnehmer ausgesucht, damit keine unfairen Vergleichsbedingungen entstehen. Für kleine Stichproben ist das eine gute Alternative zur reinen Zufallsstichprobe. Wir können uns also einfach die IQ-Werte nach dem Experiment anschauen und vergleichen.
      
      Auch für den t-Test und für andere Signifikanztests wird eine Art Kennwert berechnet, in diesem Fall der t-Wert. Die Formel lautet:
      
      $$t = \frac{\overline{x1} - \overline{x2}}{\mathit{SEM}_D}$$
      
      Wir teilen also den Mittelwertunterschied durch den Standardfehler des Mittelwertunterschieds. Denken Sie an die Standardnormalverteilung und die z-Transformation zurück. Dort wird auch durch die Standardabweichung geteilt um die Standardnormalverteilung zu erhalten. Hier beim t-Test müssen wir nicht mehr den Mittelwert der Mittelwertunterschiede von unserem Mittelwertunterschied subtrahieren, weil der ohnehin schon 0 ist. Es bleibt also nur noch das Teilen durch den Standardfehler des Mittelwertunterschieds übrig, der ja nichts anderes ist als die Standardabweichung der Mittelwertunterschiedeverteilung. Wie dem auch sei, der Zweck ist auch wieder wie bei der Standardnormalverteilung, dass man unterschiedliche t-Werte direkt vergleichen kann und mit etwas Übung leicht einschätzen kann, ob man einen signifikanten t-Wert erhalten hat. Das liegt auch wieder daran, dass sozusagen in Standardfehlern gezählt wird.
      
      Das Berechnen des Standardfehlers ist etwas aufwändiger. Dort muss nämlich die Varianz beider Stichproben integriert werden. Nachdem Sie den ausgerechnet haben, können Sie oben die Formel lösen um den t-Wert zu erhalten. Wenn die Varianzen der Stichproben klein sind, die beiden Häufigkeitsverteilungen also schmal und hoch sind, wird der Standardfehler und damit auch der t-Wert eher größer sein als wenn die Varianzen groß sind. Zunächst beginnen Sie, als würden sie für beide Stichproben die Varianz berechnen. 
      
      1. Bilden Sie für beide Stichproben die quadrierten Abweichungen zu ihrem jeweiligen Mittelwert und bilden sie daraus eine Summe. Bei der einfachen Varianz würden Sie die quadrierten Differenzen zum Mittelwert summieren, hier summieren sie die beider Stichproben
      2. Diese Summe teilen Sie durch (n1−1)+(n2−1). Das ist die Summe der beiden Stichprobengrößen, von denen sie jeweils 1 subtrahieren. Jetzt ist das Ganze eine Art Doppelvarianz geworden. Wenn Sie sich an den Schätzer der Populationsvarianz erinnern, dort wird ebenfalls durch n−1 geteilt statt durch n.
      3. Multiplizieren Sie die bisher ausgerechnete „Doppelvarianz“ mit $\frac{1}{n_1} + \frac{1}{n_2}$
      4. Ziehen Sie die Wurzel dieses Produkts, auch dies ist eine Parallele zur Standardabweichungsberechnung. Nun haben Sie den Standardfehler des Mittelwertunterschieds berechnet.
  - _id: 54caa107aa9e83ef4888fa91
    title: t-Test
    subtitle: Die t-Verteilung
    body: |
      Wenn der t-Wert berechnet ist, muss er mit der Verteilung der Mittelwertunterschiede abgeglichen werden, ob er weit genug außen liegt, also im Signifikanzbereich. Da der t-Wert eine Art z-transformierter Wert ist, läge die Annahme nahe, dass wir ihn nun mit einer Standardnormalverteilung abgleichen. Im Grunde tun wir das auch, aber für den t-Test hat sie noch ein mathematisches Extra-Feature bekommen und heißt mit diesem speziellen Feature t-Verteilung. Es besteht darin, dass diese Verteilung zwar immer einen Mittelwert von 0 und eine Standardabweichung von 1 annimmt, aber zusätzlich noch den so genannten Freiheitsgrad als dritten Parameter aufnimmt, der die Verteilung leicht mit verändert. Der Freiheitsgrad wird berechnet mit der Formel $\mathit{df} = (n_1−1)+(n_2−1)$. Er ist also unmittelbar von beiden Stichprobengrößen abhängig. Je nach dem, wie groß unsere Stichproben und unser Freiheitsgrad sind, müssen wir unseren t-Wert mit der entsprechenden t-Verteilung abgleichen. Unten auf dieser Seite finden Sie eine Anwendung, die Sie den gewünschten Freiheitsgrad auswählen lässt und ihnen die entsprechende t-Verteilung plottet. Die Verteilung ist mit einer Normalverteilung hinterlegt um zu verdeutlichen, dass sich die t-Verteilung immer mehr der Normalverteilung annähert, je größer der Freiheitsgrad ist. 
      
      Stellen Sie unten den Freiheitsgrad unseres Beispiels ein und vergleichen Sie den unter der Grafik angezeigten t-Wert mit ihrem errechneten t-Wert. Der angezeigte Wert wird als kritischer t-Wert bezeichnet und kennzeichnet die Stelle der Verteilung, ab der nach außen hin der 5%-Anteil beginnt. Der berechnete Wert ist der empirische t-Wert und muss mindestens so groß sein wie der kritische, also in diesem 5%-Flächenanteil liegen, damit das Ergebnis als signifikant bezeichnet werden kann. Wenn der berechnete Wert negativ ist, können Sie auch einfach seinen Betrag verwenden, also das Minuszeichen ignorieren. Die t-Verteilung ist symmetrisch und hat einen Mittelwert von 0.
  - _id: 54caa1b3aa9e83ef4888fa92
    title: Fehler erster und zweiter Art
    body: |
      Sie haben wahrscheinlich schon herausgefunden, dass unser t-Wert nicht signifikant ist. Er setzt sich folgendermaßen zusammen:
      
      - Der Mittelwertunterschied der beiden Gruppen beträgt einen iQ-Punkt (107 − 106 = 1). 
      - Der Standardfehler des Mittelwertunterschieds beträgt SEMD = 6.21289.
      - $t(8) = 1/\mathit{SEM}_D = 0.161$
      
      Dieser t-Wert ist deutlich kleiner als der kritische und damit nicht signifikant. Das heißt, es gibt keinen bedeutsamen Gruppenunterschied zwischen Einzel- und Gruppentraining. Das ist inhaltlich erfreulich, weil Gruppentrainings ökonomischer sind und gut in den Unterricht integriert werden können. Man will somit nicht bei jeder Signifikanzuntersuchung auch ein signifikantes Ergebnis. Wie wird aber das Signifikanzniveau festgelegt und welche Kriterien spielen dabei eine Rolle? Dieses Thema kann als Spannungsfeld charakterisiert werden. Sie können das Niveau entweder erhöhen oder verringern, und beides hat seine Vor- und Nachteile hinsichtlich der Inferenzen. 
      
      #### Fehler erster Art ("falscher Alarm")
      Der Fehler erster Art unterläuft Ihnen dann, wenn Sie aus einem signifikanten Ergebnis schließen, dass die beiden Mittelwerte aus unterschiedlichen Populationen kommen, obwohl das tatsächlich nicht der Fall ist. Laut Zahlen scheint ein Bedeutsamer Unterschied zwischen den verglichenen Gruppen zu bestehen, obwohl das im Allgemeinen tatsächlich nicht zutrifft. Sie erinnern sich, der 5%-Flächenanteil ist ja eigentlich noch ein Anteil der Mittelwertunterschiede, die aus der selben Population kommen. Dass diese extremen Unterschiede dennoch auftreten, ist nur so unwahrscheinlich (5%), dass wir dann eher einen signifikanten Mittelwertunterschied annehmen. Diese 5% sind nun auch die Wahrscheinlichkeit für einen Fehler erster Art. Das heißt, mit einer Wahrscheinlichkeit von 5% ist ein statistisch (zahlenmäßig) signifikantes Ergebnis nicht inhaltlich signifikant und die beiden verglichenen Mittelwerte stammen aus der selben Population. 
      
      Was könnten Sie mit dem Signifikanzniveau machen, damit das Risiko für den Fehler erster Art geringer wird? 
      
      #### Fehler zweiter Art ("übersehen")
      Das Gegenstück ist der Fehler zweiter Art. Dabei besteht ein tatsächlicher signifikanter Unterschied, drückt sich aber nicht in der Statistik aus und wird deswegen zunächst als nicht signifikant betrachtet. Die Mittelwerte kommen zwar tatsächlich aus verschiedenen Populationen, der Unterschied der Stichproben ist aber nicht extrem genug für unser angelegtes Signifikanzniveau. Das Problem ist, dass die Wahrscheinlichkeit für diesen Fehler besonders erhöht wird, wenn wir versuchen, die Wahrscheinlichkeit für den Fehler erster art zu reduzieren. Wenn wir das tun, bspw. das Signifikanzniveau auf 1% verringern, passiert uns zwar nur noch in einem von 100 Fällen ein Fehler erster Art, aber der Fehler zweiter Art wird wahrscheinlicher. Das liegt daran, dass die t-Werte extremer werden müssen um im äußeren 1%-Flächenanteil zu landen und als statistisch signifikant zu gelten. Die Wahrscheinlichkeit für den Fehler zweiter art ist leider schwieriger zu quantifizieren.
      
      #### Der Kompromiss
      Das Spannungsfeld ist hier, dass sich das Risiko für den einen Fehler erhöht, wenn wir versuchen, das Risiko für den anderen Fehler zu reduzieren. Jedes Signifikanzniveau ist daher ein Kompromiss aus beidem und das Signifikanzniveau von 5% haben sich in den Sozialwissenschaften als guter, schneller Kompromiss etabliert. Die Entscheidung, welchen Fehler Sie eher riskieren möchten, ist jedoch mehr eine inhaltliche als eine rein statistische Frage. Rauchmelder oder HIV-Schnelltests neigen mehr zum Fehler erster Art, weil sie lieber manchmal falschen Alarm schlagen als tatsächlich signifikante Fälle übersehen sollen. Diese Art von Tests wird als sensitiv bezeichnet. Das Gegenstück dazu wären Tests mit sehr geringem Signifikanzniveau, das die Wahrscheinlichkeit des Fehlers erster Art reduziert, aber die für den Fehler zweiter Art erhöht. Solche Tests werden als spezifisch bezeichnet. Wenn die Diagnose einer bestimmten psychischen Krankheit große Konsequenzen für den Patienten hat, sind die Diagnoseinstrumente auch eher spezifisch als sensitiv ausgelegt um keine Fehldiagnosen zu stellen für den Preis einiger nicht erkannter Erkrankungen. An dieser Stelle soll Ihnen wieder bewusst gemacht werden, dass Statistik erst dann einen Sinn erhält, wenn sie auf den Inhalt bezogen eingesetzt wird.
  - _id: 54caa28caa9e83ef4888fa93
    title: t-Test für gepaarte Stichproben
    body: |
      Nun wissen wir immer noch nicht, ob die Trainings funktionieren. Das können wir ebenfalls mit einem t-Test herausfinden. Die Frage hinsichtlich unseres Datensatzes würde lauten: Sind die Teilnehmer nach dem Training signifikant intelligenter als davor? Wir vergleichen also die Variable Intelligenz_vorher mit Intelligenz_nachher. Eine Besonderheit ist hier nun, dass die beiden Stichproben nicht unabhängig voneinander sind. Das sind nicht zwei Stichproben, die unabhängig voneinander gezogen wurden, sondern für jeden Teilnehmer gibt es einen Vorher- und einen Nachher-Wert. Im vorigen Beispiel waren es unabhängige Stichproben und da ging es wirklich um den Unterschied der beiden Stichprobenmittelwerte. Diesmal interessieren wir uns für die Unterschiede innerhalb der Wertepaare. Es spielt also diesmal nicht der Intelligenzunterschied zwischen den Teilnehmern eine Rolle, sondern wie stark sich die Teilnehmer für sich genommen verbessert haben. Man könnte auch sagen, es geht nicht mehr um Mittelwertunterschiede (Differenz zwischen zwei Mittelwerten), sondern den Mittelwert der Differenzen (Mittelwert aller Wertepaardifferenzen). Damit das etwas verständlicher wird, rechnen Sie jetzt den t-Test für paarige Stichproben durch. Insgesamt gestaltet sich die Berechnung recht ähnlich wie die des Tests für unabhängige Stichproben. Mittlere Wertepaardifferenzen sind auch normalverteilt und diese Verteilung hat einen Mittelwert von 0. Es funktioniert somit noch recht ähnlich wie beim t-Test für unabhängige Stichproben. 
      
      1. Die Formel für den t-Wert lautet: 
      $$t = \frac{\overline{x_d}}{\mathit{SEM}_d}$$
      
      Wir teilen den Mittelwert der Differenzen durch den Standardfehler des Mittelwertes von Differenzen. Dieser Standardfehler ist sozusagen die Standardabweichung, mit der die Mittelwerte von Differenzen um die 0 streuen. Es wird demnach wieder z-transformiert.
      2. Die Wertepaardifferenzen erhalten Sie, indem Sie für jeden Teilnehmer die Intelligenz nachher von der Intelligenz vorher subtrahieren. Anschließend bilden Sie den Mittelwert dieser Differenzen.
      3. Diesmal ist der Standardfehler ein Standardfehler des Mittelwertes, auch wenn hier Mittelwerte von Differenzen gemeint sind. Wenn Sie noch aus dem Kapitel zur Inferenzstatistik wissen, wie man einen Populationsmittelwert schätzt, könnten Sie schon eine Idee haben, wie es hier weitergeht. Dort wird die Standardabweichung der Stichprobe berechnet und durch die Wurzel der Stichprobengröße geteilt um den Standardfehler des Mittelwertes zu erhalten. Das können Sie hier genauso machen, nämlich die Standardabweichung der Wertepaardifferenzen berechnen und durch die Wurzel der Anzahl der Wertepaardifferenzen (15 Wertepaare) teilen. Vergessen Sie nicht, bei der Varianz durch n−1 statt durch n zu teilen, weil das ein inferenzstatistischer Schätzer ist und kein bloßer Stichprobenkennwert.
      4. Teilen Sie den Mittelwert der wertepaardifferenzen durch den Standardfehler und prüfen ihn in der t-Verteilung. Der Freiheitsgrad orientiert sich jetzt nicht mehr an der Anzahl der Werte in den beiden Stichproben, sondern an der Anzahl der Wertedifferenzen \\((nd): df=nd−1\\). Sie müssen somit 1 von der Anzahl der wertepaare subtrahieren. Mit dieser Information können Sie Ihren errechneten t-Wert unten prüfen.
  - _id: 54caa33eaa9e83ef4888fa94
    title: Fazit
    body: |
      Wenn alles bei der Berechnung funktioniert hat, sollten Sie folgende Werte ermittelt haben:
      
      - Mittelwert der Differenzen \\(\overline{xd} = −6\\)
      - Standardfehler des Mittelwertes der Differenzen \\(SEMd = 0.2182179\\)
      - Prüfwert \\(t(14)=27.49545\\)
      
      Falls sie etwas stärker gerundet haben, ist das kein Problem, aber es sollte schon ungefähr übereinstimmen. Wenn Sie diesen Wert mit dem kritischen t-Wert geprüft haben, werden Sie festgestellt haben, dass dieses Ergebnis signifikant ist. Inhaltlich heißt das, die Intelligenz vorher und nachher unterscheiden sich signifikant voneinander. Der Test sagt nicht, ob zum besseren oder zum Schlechteren, das sehen Sie erst an den Rohdaten. Der Mittelwert der Differenzen ist negativ (−6) und wir haben die Nachher-Werte von den Vorher-Werten subtrahiert, also müssen die Nachher-Werte im Mittel größer sein als die Vorher-Werte und die Intelligenz sich zum Guten hin geändert haben.
      
      Sie haben nun einiges über signifikanztests gelernt und auf welche Fragestellungen sie angewendet werden, nämlich zur Untersuchung von Mittelwertunterschieden. Es wurde auch angesprochen, dass statistische Signifikanz nicht immer zwangsläufig auch inhaltliche Signifikanz bedeuten muss. Sie haben den t-Test als Beispieltest kennengelernt, es gibt aber noch viel mehr Tests und Verteilungen, die ebenso eine Modifikation des Grundprinzips sind und auf bestimmte Fragestellungen zugeschnitten sind. Mit dem Gelernten könnten Sie auch in der Lage sein, sich ggf. einen solchen Test anzueignen.